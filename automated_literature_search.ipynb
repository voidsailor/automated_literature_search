{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated literature search\n",
    "\n",
    "__Author:__ \\\n",
    "Emanuel Lange \\\n",
    "Mehrdimensionale OMICS-Datenanalyse \\\n",
    "ISAS e.V. \\\n",
    "Bunsen-Kirchhoff-Stra√üe 11 \\\n",
    "44139 Dortmund, Germany \\\n",
    "emanuel.lange@isas.de\n",
    "\n",
    "__Last Revision:__ \\\n",
    "December 18, 2023\n",
    "\n",
    "__License:__ \\\n",
    "MIT\n",
    "\n",
    "__Objective:__ \\\n",
    "This script queries PubMed and extracts the most cited reference articles from the initial query.\n",
    "It was used for a literature on microbiome modeling (submission pending). Pubmed queries used in this review are listed below. The generated outputs for these queries are included in the directory './review_query_outputs'.\n",
    "\n",
    "This was inspired by the project of Paula Martin Gonzalez: https://github.com/paulamartingonzalez/Targeted_Literature_Reviews_via_webscraping/tree/main\n",
    "\n",
    "__How it works:__ \\\n",
    "Articles are retrieved via the PubMed API.\n",
    "For interactive visualization we utilized the bokeh library (http://bokeh.org/). \\\n",
    "Visualizations and data are stored as html documents and can be viewed using any modern web-browser.\n",
    "\n",
    "__How to execute:__ \\\n",
    "Jupyter-notebooks are comprised of cells (text and code) that can be executed by CTRL + ENTER (executes selected cell) or SHIFT + ENTER (executes selected cell and jumps to next one).\n",
    "\n",
    "Before running this script, make sure you installed and activated the provided CONDA environment. \n",
    "\n",
    "Execute every cell below the sections 1 and 2 to make all functions available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7YmvedPz5h-"
   },
   "source": [
    "# 1) Import Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncommend the line below if you work in google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZoWIqzTQJUP_"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display # for showing dataframes in jupyter notebook\n",
    "import openpyxl # xlsx export\n",
    "import pandas as pd # xlsx export\n",
    "from Bio import Entrez # pubmed querying\n",
    "import networkx as nx # calculating spring layout for graph\n",
    "from time import time # measuring duration of search\n",
    "\n",
    "# interactive visualization\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.models import (BoxZoomTool, Circle, HoverTool,\n",
    "                          MultiLine, Plot, Range1d, ResetTool, WheelZoomTool, PanTool, GraphRenderer, StaticLayoutProvider, TapTool, NodesAndLinkedEdges)\n",
    "from bokeh.palettes import Spectral4\n",
    "from bokeh.transform import factor_cmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQjRqUeEihgf"
   },
   "source": [
    "# 2) Classes and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo84x61hE-li"
   },
   "source": [
    "## 2.1) Article Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RsTf2krAEEmw"
   },
   "outputs": [],
   "source": [
    "class Article:\n",
    "  \"\"\"Class to store article information retrieved from pubmed queries.\"\"\"\n",
    "  pmid = ''\n",
    "  doi = ''\n",
    "  title = ''\n",
    "  firstAuthorName = ''\n",
    "  year = ''\n",
    "  isReference = False\n",
    "  references = []\n",
    "  incomingEdgeNumber = 0\n",
    "\n",
    "  def __init__(self, pmid, doi, title, firstAuthorName, year, isReference, references):\n",
    "    self.pmid = pmid\n",
    "    self.doi = doi\n",
    "    self.title = title\n",
    "    self.firstAuthorName = firstAuthorName\n",
    "    self.year = year\n",
    "    self.isReference = isReference\n",
    "    self.references = references\n",
    "\n",
    "  def getPropsAsDict(self):\n",
    "    return self.__dict__\n",
    "\n",
    "  def getPropsAsList(self):\n",
    "    return [self.title, str(self.isReference), self.doi, str(self.incomingEdgeNumber), self.references]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Functions for Pubmed search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "s1KABabfPltO"
   },
   "outputs": [],
   "source": [
    "def search(query, max_return):\n",
    "    handle = Entrez.esearch(db='pubmed',\n",
    "                            sort='relevance',\n",
    "                            retmax=str(max_return),\n",
    "                            retmode='xml',\n",
    "                            term=query)\n",
    "    results = Entrez.read(handle)\n",
    "    return results['IdList']\n",
    "\n",
    "def fetch_details(id_list):\n",
    "    id_string = ','.join([str(id) for id in id_list])\n",
    "    handle = Entrez.efetch(db='pubmed',\n",
    "                           retmode='xml',\n",
    "                           id=id_string)\n",
    "    results = Entrez.read(handle)\n",
    "    return results\n",
    "\n",
    "def get_ids_from_article_id_list(article_id_list):\n",
    "    \"\"\"Parses electronic article ids from the provided object\"\"\"\n",
    "    id_types = [id.attributes['IdType'] for id in article_id_list]\n",
    "    ids = [str(id) for id in article_id_list] # transform entries to str\n",
    "    return dict(zip(id_types, ids)) # transform to dict\n",
    "\n",
    "def update_dict(updated_dict, dict_for_update):\n",
    "\n",
    "  for key in dict_for_update:\n",
    "    if key in updated_dict:\n",
    "      continue\n",
    "\n",
    "    updated_dict.update({key: dict_for_update[key]}) # add reference entries to the article dict\n",
    "\n",
    "def update_and_save_articles(article_dict, output_file_prefix):\n",
    "\n",
    "  # dict for excel output and network graph\n",
    "  output_dict = {\n",
    "      'pmid': [],\n",
    "      'title': [],\n",
    "      'first author': [],\n",
    "      'year': [],\n",
    "      'degree': [],\n",
    "      'doi': [],\n",
    "      'is reference': [],\n",
    "      'references': []\n",
    "  }\n",
    "    \n",
    "  for article_key in article_dict:\n",
    "\n",
    "    if article_dict[article_key].isReference:\n",
    "        continue\n",
    "    \n",
    "    # iterate over references of the intial articles and update the incoming edge number if a reference is included\n",
    "    for reference_key in article_dict[article_key].references:\n",
    "      if reference_key in article_dict:\n",
    "        article_dict[reference_key].incomingEdgeNumber += 1\n",
    "\n",
    "  for article_key in article_dict:\n",
    "    article_obj = article_dict[article_key]\n",
    "      \n",
    "    output_dict['pmid'].append(article_obj.pmid)  \n",
    "    output_dict['title'].append(article_obj.title)\n",
    "    output_dict['first author'].append(article_obj.firstAuthorName)\n",
    "    output_dict['year'].append(article_obj.year)\n",
    "    output_dict['degree'].append(int(article_obj.incomingEdgeNumber))\n",
    "    output_dict['doi'].append(article_obj.doi)\n",
    "    output_dict['is reference'].append(str(article_obj.isReference))\n",
    "    output_dict['references'].append(article_obj.references)\n",
    "\n",
    "  output_data = pd.DataFrame.from_dict(output_dict)\n",
    "  display(output_data)\n",
    "  output_data.to_excel(output_file_prefix + '_list.xlsx')\n",
    "\n",
    "  return output_dict\n",
    "\n",
    "def get_articles_from_pmids(pmid_list, isReferenceSearch, batch_size):\n",
    "    \"\"\"Retrieves articles from PubMed based on a list of pmids.\n",
    "    pmid_list: list of pubmed ids\n",
    "    isReferenceSearch: boolean, whether the articles are references or not, set to true during the search for references\n",
    "    batch_size: int, the number of articles to retrieve at once from the pubmed API\"\"\"\n",
    "\n",
    "    article_dict = {} # dictionary for article objects\n",
    "    number_of_references = 0 # total number of references\n",
    "    number_of_missing_references = 0 # total number of references that do not have a pubmed id\n",
    "\n",
    "    # iterate over over pubmed ids in batches of batch_size\n",
    "    for batch_start_entry in range(0, len(pmid_list), batch_size):\n",
    "\n",
    "      batch_ids = pmid_list[batch_start_entry : batch_start_entry + batch_size]\n",
    "      batch_results = fetch_details(batch_ids) # retrieves article objects from pubmed for the batch of provided ids\n",
    "\n",
    "      # iterate over the article objects in the batch and write data into the article_dict\n",
    "      for article_obj in batch_results['PubmedArticle']:\n",
    "        # try:\n",
    "          data = article_obj.get('MedlineCitation')\n",
    "          title = data.get('Article').get('ArticleTitle')\n",
    "          \n",
    "          authorName = ''\n",
    "          year = ''\n",
    "          \n",
    "          try:\n",
    "            authorName = data.get('Article').get('AuthorList')[0].get('LastName')\n",
    "            year = data.get('Article').get('ArticleDate')[0].get('Year')\n",
    "          except:\n",
    "            pass\n",
    "\n",
    "          pubmed_data = article_obj.get('PubmedData') # pubmed metadata\n",
    "\n",
    "          article_id_objects = pubmed_data.get('ArticleIdList') # object of electronic article ids\n",
    "\n",
    "          try:\n",
    "            id_obj = get_ids_from_article_id_list(article_id_objects) # get list of electronic article ids\n",
    "          except:\n",
    "            print('Article \"' + title + '\" was excluded, because it had no identifiers.')\n",
    "            continue\n",
    "          \n",
    "          # check whether pubmed id is available\n",
    "          try:\n",
    "            pmid = int(id_obj['pubmed'])\n",
    "          except:\n",
    "            print('Article \"' + title + '\" was excluded, because it had no pubmed identifier.')\n",
    "            continue\n",
    "\n",
    "          doi = id_obj.get('doi') # will be None if doi is not available\n",
    "\n",
    "          number_of_article_references = 0\n",
    "          number_of_missing_article_references = 0 # count references that do not have a pubmed id\n",
    "          paper_references = []\n",
    "\n",
    "          # read reference objects from article object\n",
    "          try:\n",
    "            paper_references = pubmed_data.get('ReferenceList')[0]['Reference']\n",
    "            number_of_article_references = len(paper_references)\n",
    "          except:\n",
    "            # print('Article ' + pmid + ' has no references')\n",
    "            pass\n",
    "\n",
    "          reference_ids = []\n",
    "\n",
    "          # read electronic reference ids from reference objects\n",
    "          for ref in paper_references:\n",
    "            try:\n",
    "              reference_id_obj = get_ids_from_article_id_list(ref.get('ArticleIdList'))\n",
    "              reference_ids.append(int(reference_id_obj['pubmed'])) # throws exception if no pubmed id\n",
    "              if int(reference_id_obj['pubmed']) == 0:\n",
    "                raise Exception('Zero identifier') # Some entries have zero as identifier, which should be excluded\n",
    "            except:\n",
    "              number_of_missing_article_references += 1\n",
    "              continue\n",
    "\n",
    "          # print(str(missing_id_count) + ' references included due to lack of identifiers for article ' + pmid)\n",
    "          number_of_references += number_of_article_references\n",
    "          number_of_missing_references += number_of_missing_article_references\n",
    "\n",
    "          article_dict[pmid] = Article(\n",
    "                  pmid,\n",
    "                  doi,\n",
    "                  title,\n",
    "                  authorName,\n",
    "                  year,\n",
    "                  references=reference_ids,\n",
    "                  isReference=isReferenceSearch)\n",
    "\n",
    "        # except:\n",
    "        #   print('Article excluded due to unknown reason')\n",
    "\n",
    "      missing_ref_ratio = 0\n",
    "\n",
    "      if not number_of_references == 0:\n",
    "        missing_ref_ratio = number_of_missing_references / number_of_references # calculate fraction of references without pubmed id\n",
    "          \n",
    "    return article_dict, missing_ref_ratio\n",
    "\n",
    "def get_reference_articles(article_dict, batch_size):\n",
    "\n",
    "  all_reference_article_dict = {}\n",
    "  number_of_articles = len(article_dict)\n",
    "\n",
    "  for index, article_key in enumerate(article_dict):\n",
    "    print('Checking article ' + str(index+1) + ' of ' + str(number_of_articles), end='\\r')\n",
    "    article = article_dict[article_key]\n",
    "\n",
    "    # retrieve references for each article\n",
    "    if len(article.references) > 0:\n",
    "      reference_articles, missing_ref_fraction = get_articles_from_pmids(article.references, True, batch_size)\n",
    "      all_reference_article_dict.update(reference_articles)\n",
    "\n",
    "  return all_reference_article_dict\n",
    "\n",
    "def get_articles_and_primary_references(query, output_file_prefix, number_of_initial_articles, batch_size):\n",
    "  \"\"\"Function to retrieve articles and their references from PubMed.\n",
    "  query: string, the query to search for\n",
    "  output_file_prefix: string, the prefix for the output file\n",
    "  number_of_initial_articles: int, the number of initial articles to retrieve\n",
    "  batch_size: int, the number of articles to retrieve at once from the pubmed API\n",
    "  \"\"\"\n",
    "\n",
    "  start_time = time()\n",
    "\n",
    "  print('Started search for your query...')\n",
    "  results_id_list = search(query, number_of_initial_articles) # get initial list of article ids\n",
    "  initial_articles, missing_reference_fraction = get_articles_from_pmids(results_id_list, isReferenceSearch=False, batch_size=batch_size) # get initial article objects\n",
    "  print('Done with initial articles, fetching references...')\n",
    "\n",
    "  reference_articles = get_reference_articles(initial_articles, batch_size=batch_size) # get reference article objects\n",
    "\n",
    "  end_time = time()\n",
    "\n",
    "  print(\"I found \" + str(len(reference_articles)) + \" references in \" + str(len(initial_articles)) + \" initial articles for query \" + query)\n",
    "  print(\"%5.1f percent of the initial articles had no references in pubmed central.\" % (missing_reference_fraction * 100))\n",
    "\n",
    "  print(\"Search took \" + str((end_time-start_time)/60) + \" minutes\")\n",
    "  update_dict(initial_articles, reference_articles) # append references to the initial article dict\n",
    "\n",
    "  print('Counting references and writing xlsx...')\n",
    "  article_data_list = update_and_save_articles(initial_articles, output_file_prefix)\n",
    "\n",
    "  print('Done')\n",
    "  return article_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpEVAyBDKrkJ"
   },
   "source": [
    "## 2.3) Functions for interactive graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Oqw6N3AgKj7c"
   },
   "outputs": [],
   "source": [
    "def add_hover(p):\n",
    "    \"\"\"hover tooltip for data points\"\"\"\n",
    "\n",
    "    # custom tooltip layout\n",
    "    t = \"\"\"\n",
    "    <div @tooltip{custom} >\n",
    "        <b>pubmed id: </b> @index <br>\n",
    "        <b>title: </b> @title <br>\n",
    "        <b>first author: </b> @firstAuthor <br>\n",
    "        <b>year: </b> @year <br>\n",
    "        <b>doi: </b> @doi <br>\n",
    "        <b>in degree: </b> @degree <br>\n",
    "    </div>\n",
    "    <style>\n",
    "    div.bk-tooltip-content > div > div:not(:first-child) {\n",
    "        display:none !important;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "\n",
    "    # initiate and add hover tool to display tooltips\n",
    "    hover = HoverTool()\n",
    "    hover.tooltips = t\n",
    "    p.add_tools(hover)\n",
    "\n",
    "def build_graph(article_data_list, output_file_prefix):\n",
    "  \"\"\"Creates an interactive visualization of the reference network and outputs it as html file. The html can be viewed in any modern webbrowser.\n",
    "    article_data_list: dict, the output of get_articles_and_primary_references function\n",
    "    output_file_prefix: string, the prefix for the output file\n",
    "  \"\"\"\n",
    "\n",
    "  nodes = []\n",
    "  edges = []  # edges to calculate spring layout\n",
    "\n",
    "  # edge sources and targets for edge renderer\n",
    "  edge_sources = []\n",
    "  edge_targets = []\n",
    " \n",
    "  # create nodes and edges for graph\n",
    "  for article_index in range(0, len(article_data_list['pmid'])):\n",
    "\n",
    "    article_key = article_data_list['pmid'][article_index]\n",
    "\n",
    "    nodes.append(article_key)\n",
    "\n",
    "    if article_data_list['is reference'][article_index] == \"True\":\n",
    "      continue\n",
    "\n",
    "    for ref in article_data_list['references'][article_index]:\n",
    "      edges.append((article_key, ref))\n",
    "      edge_sources.append(article_key)\n",
    "      edge_targets.append(ref)\n",
    "\n",
    "  # calculate spring layout\n",
    "  graph = nx.Graph()\n",
    "  graph.add_nodes_from(nodes)\n",
    "  graph.add_edges_from(edges)\n",
    "  pos = nx.spring_layout(graph, iterations=50, scale=4)\n",
    "\n",
    "  # initialize interactive plot  \n",
    "  plot = Plot(\n",
    "      x_range=Range1d(-1.1, 1.1),\n",
    "      y_range=Range1d(-1.1, 1.1),\n",
    "      width=1200,\n",
    "      height=1000\n",
    "      )\n",
    "  \n",
    "  # initialize graph renderer\n",
    "  graph_renderer = GraphRenderer()\n",
    "  \n",
    "  ## nodes\n",
    "  # add nodes to renderer\n",
    "  graph_renderer.node_renderer.glyph = Circle(\n",
    "      fill_color=factor_cmap(\"isReference\", (Spectral4[0], Spectral4[2]), [\"True\", \"False\"]), radius=0.01, fill_alpha=0.8)\n",
    "  \n",
    "  # define color and mode of selected nodes\n",
    "  graph_renderer.node_renderer.selection_glyph = Circle(fill_color=Spectral4[3])\n",
    "  graph_renderer.selection_policy = NodesAndLinkedEdges()\n",
    "  \n",
    "  # add data to renderer\n",
    "  graph_renderer.node_renderer.data_source.data = dict(\n",
    "      index=article_data_list['pmid'],\n",
    "      title=article_data_list['title'],\n",
    "      firstAuthor=article_data_list['first author'],\n",
    "      year=article_data_list['year'],\n",
    "      doi=article_data_list['doi'],\n",
    "      isReference=article_data_list['is reference'],\n",
    "      degree=article_data_list['degree']\n",
    "      )\n",
    "\n",
    "  ## edges\n",
    "  # add edges to renderer\n",
    "  graph_renderer.edge_renderer.glyph = MultiLine(line_width=2, line_alpha=0.2)\n",
    "\n",
    "  # define color and mode of selected edges\n",
    "  graph_renderer.edge_renderer.selection_glyph = MultiLine(line_width=2\n",
    "                                                           , line_color=Spectral4[3])\n",
    "  # add data to edge renderer\n",
    "  graph_renderer.edge_renderer.data_source.data = dict(\n",
    "      start=edge_sources,\n",
    "      end=edge_targets\n",
    "      )\n",
    "  \n",
    "  # pass spring layout into graph renderer\n",
    "  graph_renderer.layout_provider = StaticLayoutProvider(graph_layout=pos)\n",
    "\n",
    "  # add graph renderer to plot\n",
    "  plot.renderers.append(graph_renderer)\n",
    "  \n",
    "  # add tools to plot\n",
    "  plot.add_tools(BoxZoomTool(), ResetTool(), WheelZoomTool(), PanTool(), TapTool())\n",
    "  add_hover(plot)\n",
    "  \n",
    "  # output graph as html file\n",
    "  output_file(output_file_prefix + \"_graph.html\")\n",
    "  # output_notebook() # uncomment if you want to display the graph in this notebook\n",
    "  show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Execute Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PubMed queries used in the manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = '(microbiome) OR (microbial community)'\n",
    "# query = '(meta proteomics) OR (meta genomics) OR (meta omics)'\n",
    "# query = '(computational model) AND ((metabolism) OR (regulation) OR (signaling))'\n",
    "# query = '(biological network reconstruction) AND ((microbiome) OR (microbial community))'\n",
    "# query = '(computational model) AND ((parameter estimation) OR (contextualization) OR (reduction))'\n",
    "# query = '(computational modeling) AND ((microbiome) OR (microbial community))'\n",
    "# query = '(control algorithm) AND ((microbiome) OR (microbial community))'\n",
    "# query = '(network modeling) AND (guidelines OR software OR repository)'\n",
    "\n",
    "query = 'microbiome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file_prefix = \"07_11_23_microbiome_or_microbial_community_100\"\n",
    "# output_file_prefix = \"07_11_23_meta_proteomics_or_meta_genomics_or_meta_omics_100\"\n",
    "# output_file_prefix = \"07_11_23_computational_modeling_and_metabolism_or_regulation_or_signaling_100\"\n",
    "# output_file_prefix = '07_11_23_biological_network_reconstruction_and_microbiome_or_microbial_community_100'\n",
    "# output_file_prefix = '07_11_23_computational_modeling_and_parameter_estimation_or_contextualization_or_reduction_100'\n",
    "# output_file_prefix = '07_11_23_computational_modeling_and_microbiome_or_microbial_community_100'\n",
    "# output_file_prefix = '07_11_23_control_algorithm_and_microbiome_or_microbial_community_100'\n",
    "# output_file_prefix = '07_11_23_network_modeling_and_guidelines_or_software_or_repository_100'\n",
    "\n",
    "output_file_prefix = 'test_microbiome_10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A registered email and an api key are required to access the PubMed API. More information here: https://ncbiinsights.ncbi.nlm.nih.gov/2017/11/02/new-api-keys-for-the-e-utilities/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The api key is optional, but you can get more articles without error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.api_key = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for your query and generate an output as xlsx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started search for your query...\n",
      "Done with initial articles, fetching references...\n",
      "I found 848 references in 10 initial articles for query microbiome\n",
      " 14.7 percent of the initial articles had no references in pubmed central.\n",
      "Search took 0.7867766340573629 minutes\n",
      "Counting references and writing xlsx...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>title</th>\n",
       "      <th>first author</th>\n",
       "      <th>year</th>\n",
       "      <th>degree</th>\n",
       "      <th>doi</th>\n",
       "      <th>is reference</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29171095</td>\n",
       "      <td>The Gastrointestinal Microbiome: A Review.</td>\n",
       "      <td>Barko</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>10.1111/jvim.14875</td>\n",
       "      <td>False</td>\n",
       "      <td>[25394236, 17943116, 22411464, 15272194, 16478...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29282061</td>\n",
       "      <td>The human microbiome in evolution.</td>\n",
       "      <td>Davenport</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>10.1186/s12915-017-0454-7</td>\n",
       "      <td>False</td>\n",
       "      <td>[28375652, 21871249, 23391737, 21682646, 12089...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35393656</td>\n",
       "      <td>The human microbiome in disease and pathology.</td>\n",
       "      <td>Manos</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "      <td>10.1111/apm.13225</td>\n",
       "      <td>False</td>\n",
       "      <td>[21722791, 22699609, 24997786, 32102216, 20624...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32345639</td>\n",
       "      <td>Advances in Understanding the Human Urinary Mi...</td>\n",
       "      <td>Neugent</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>10.1128/mBio.00218-20</td>\n",
       "      <td>False</td>\n",
       "      <td>[22699609, 28953883, 22699610, 24371246, 22047...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28096237</td>\n",
       "      <td>The Human Microbiome and Cancer.</td>\n",
       "      <td>Rajagopala</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>10.1158/1940-6207.CAPR-16-0249</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>28398304</td>\n",
       "      <td>Engineered probiotic Escherichia coli can elim...</td>\n",
       "      <td>Hwang</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1038/ncomms15028</td>\n",
       "      <td>True</td>\n",
       "      <td>[26464014, 18074031, 18240278, 15708311, 19364...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>24259713</td>\n",
       "      <td>Gnotobiotic mouse model of phage-bacterial hos...</td>\n",
       "      <td>Reyes</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1073/pnas.1319470110</td>\n",
       "      <td>True</td>\n",
       "      <td>[20147985, 19834481, 23828941, 20631792, 21880...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>29323293</td>\n",
       "      <td>Precision editing of the gut microbiota amelio...</td>\n",
       "      <td>Zhu</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1038/nature25172</td>\n",
       "      <td>True</td>\n",
       "      <td>[17699621, 18030708, 20833380, 19783002, 23843...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>31015663</td>\n",
       "      <td>Engineered commensal microbes for diet-mediate...</td>\n",
       "      <td>Ho</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1038/s41551-017-0181-y</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>28431252</td>\n",
       "      <td>Engineered Regulatory Systems Modulate Gene Ex...</td>\n",
       "      <td>Lim</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>10.1016/j.cell.2017.03.045</td>\n",
       "      <td>True</td>\n",
       "      <td>[21857964, 2231712, 11094294, 21261817, 971657...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>858 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pmid                                              title first author  \\\n",
       "0    29171095         The Gastrointestinal Microbiome: A Review.        Barko   \n",
       "1    29282061                 The human microbiome in evolution.    Davenport   \n",
       "2    35393656     The human microbiome in disease and pathology.        Manos   \n",
       "3    32345639  Advances in Understanding the Human Urinary Mi...      Neugent   \n",
       "4    28096237                   The Human Microbiome and Cancer.   Rajagopala   \n",
       "..        ...                                                ...          ...   \n",
       "853  28398304  Engineered probiotic Escherichia coli can elim...        Hwang   \n",
       "854  24259713  Gnotobiotic mouse model of phage-bacterial hos...        Reyes   \n",
       "855  29323293  Precision editing of the gut microbiota amelio...          Zhu   \n",
       "856  31015663  Engineered commensal microbes for diet-mediate...           Ho   \n",
       "857  28431252  Engineered Regulatory Systems Modulate Gene Ex...          Lim   \n",
       "\n",
       "     year  degree                             doi is reference  \\\n",
       "0    2017       0              10.1111/jvim.14875        False   \n",
       "1    2017       0       10.1186/s12915-017-0454-7        False   \n",
       "2    2022       0               10.1111/apm.13225        False   \n",
       "3    2020       0           10.1128/mBio.00218-20        False   \n",
       "4    2017       0  10.1158/1940-6207.CAPR-16-0249        False   \n",
       "..    ...     ...                             ...          ...   \n",
       "853  2017       1             10.1038/ncomms15028         True   \n",
       "854  2013       1         10.1073/pnas.1319470110         True   \n",
       "855  2018       1             10.1038/nature25172         True   \n",
       "856  2018       1       10.1038/s41551-017-0181-y         True   \n",
       "857             1      10.1016/j.cell.2017.03.045         True   \n",
       "\n",
       "                                            references  \n",
       "0    [25394236, 17943116, 22411464, 15272194, 16478...  \n",
       "1    [28375652, 21871249, 23391737, 21682646, 12089...  \n",
       "2    [21722791, 22699609, 24997786, 32102216, 20624...  \n",
       "3    [22699609, 28953883, 22699610, 24371246, 22047...  \n",
       "4                                                   []  \n",
       "..                                                 ...  \n",
       "853  [26464014, 18074031, 18240278, 15708311, 19364...  \n",
       "854  [20147985, 19834481, 23828941, 20631792, 21880...  \n",
       "855  [17699621, 18030708, 20833380, 19783002, 23843...  \n",
       "856                                                 []  \n",
       "857  [21857964, 2231712, 11094294, 21261817, 971657...  \n",
       "\n",
       "[858 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "article_data = get_articles_and_primary_references(query, output_file_prefix, number_of_initial_articles=10, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an interactive graph to explore the data, is written to html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "J3gfigUBM7Bz",
    "outputId": "090c2bd5-f3de-4f1d-fcee-61a83c885bd4"
   },
   "outputs": [],
   "source": [
    "build_graph(article_data, output_file_prefix)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
